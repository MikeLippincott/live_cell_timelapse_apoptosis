{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import tifffile\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from rich.pretty import pprint\n",
    "from stardist.models import StarDist2D\n",
    "from ultrack import to_tracks_layer, track, tracks_to_zarr\n",
    "from ultrack.config import MainConfig\n",
    "from ultrack.imgproc import normalize\n",
    "from ultrack.utils import estimate_parameters_from_labels, labels_to_contours\n",
    "\n",
    "# check if in a jupyter notebook\n",
    "\n",
    "try:\n",
    "    cfg = get_ipython().config\n",
    "    in_notebook = True\n",
    "except NameError:\n",
    "    in_notebook = False\n",
    "\n",
    "print(f\"Running in notebook: {in_notebook}\")\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "# check gpu\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if not gpu_devices:\n",
    "    print(\"No GPU found\")\n",
    "else:\n",
    "    print(\"GPU found\")\n",
    "\n",
    "\n",
    "# tensorflow clear gpu memory\n",
    "def clear_gpu_memory():\n",
    "    from numba import cuda\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not in_notebook:\n",
    "    print(\"Running as script\")\n",
    "    # set up arg parser\n",
    "    parser = argparse.ArgumentParser(description=\"Segment the nuclei of a tiff image\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--input_dir_main\",\n",
    "        type=str,\n",
    "        help=\"Path to the input directory containing the tiff images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input_dir_terminal\",\n",
    "        type=str,\n",
    "        help=\"Path to the input directory containing the tiff images\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    input_dir_main = pathlib.Path(args.input_dir_main).resolve(strict=True)\n",
    "    input_dir_terminal = pathlib.Path(args.input_dir_terminal).resolve(strict=True)\n",
    "else:\n",
    "    print(\"Running in a notebook\")\n",
    "    input_dir_main = pathlib.Path(\n",
    "        \"../../2.cellprofiler_ic_processing/illum_directory_test/20231017ChromaLive_6hr_4ch_MaxIP_C-02_F0001\"\n",
    "    ).resolve(strict=True)\n",
    "    input_dir_terminal = pathlib.Path(\n",
    "        f\"../../2.cellprofiler_ic_processing/illum_directory_test/20231017ChromaLive_endpoint_w_AnnexinV_2ch_MaxIP_{str(input_dir_main).split('MaxIP_')[1]}\"\n",
    "    ).resolve(strict=True)\n",
    "\n",
    "temporary_output_dir = pathlib.Path(\"../tmp_output\").resolve()\n",
    "figures_output_dir = pathlib.Path(\"../figures\").resolve()\n",
    "results_output_dir = pathlib.Path(\"../results\").resolve()\n",
    "temporary_output_dir.mkdir(exist_ok=True)\n",
    "figures_output_dir.mkdir(exist_ok=True)\n",
    "results_output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extensions = {\".tif\", \".tiff\"}\n",
    "# get all the tiff files\n",
    "tiff_files = list(input_dir_main.glob(\"*\"))\n",
    "tiff_files = [f for f in tiff_files if f.suffix in file_extensions]\n",
    "tiff_files = sorted(tiff_files)\n",
    "\n",
    "tiff_files_terminal = list(input_dir_terminal.glob(\"*\"))\n",
    "tiff_files_terminal = [f for f in tiff_files_terminal if f.suffix in file_extensions]\n",
    "tiff_files_terminal = sorted(tiff_files_terminal)\n",
    "\n",
    "tiff_files = tiff_files + tiff_files_terminal\n",
    "tiff_files = [f for f in tiff_files if \"C01\" in f.name]\n",
    "\n",
    "print(f\"Found {len(tiff_files)} tiff files in the input directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dims = tifffile.imread(tiff_files[0]).shape\n",
    "timelapse_raw = np.zeros(\n",
    "    (len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16\n",
    ")\n",
    "timelapse_raw_visualize = np.zeros(\n",
    "    (len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16\n",
    ")\n",
    "stardist_labels = np.zeros(\n",
    "    (len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all the images\n",
    "max_number_of_objects = 0\n",
    "print(f\"Segmenting {len(tiff_files)} images\")\n",
    "for image_index, image_file_path in tqdm.tqdm(enumerate(tiff_files)):\n",
    "    image = tifffile.imread(image_file_path)\n",
    "    timelapse_raw_visualize[image_index, :, :] = image\n",
    "    image = normalize(image, gamma=1.0)\n",
    "    timelapse_raw[image_index, :, :] = image\n",
    "\n",
    "    segmented_image, _ = model.predict_instances(image)\n",
    "    stardist_labels[image_index, :, :] = segmented_image\n",
    "    if len(np.unique(segmented_image)) > max_number_of_objects:\n",
    "        max_number_of_objects = len(np.unique(segmented_image))\n",
    "# concat all the images into one array\n",
    "print(stardist_labels.shape)\n",
    "# get the number of unqiue labels in the labels\n",
    "print(f\"Found {max_number_of_objects} unique labels in the stardist labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = np.zeros((len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16)\n",
    "edges = np.zeros((len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16)\n",
    "for frame_index, frame in enumerate(stardist_labels):\n",
    "    detections[frame_index, :, :], edges[frame_index, :, :] = labels_to_contours(frame)\n",
    "print(detections.shape, edges.shape)\n",
    "tifffile.imwrite(f\"{temporary_output_dir}/stardist_labels.tif\", stardist_labels)\n",
    "tifffile.imwrite(f\"{temporary_output_dir}/timelapse_raw.tif\", timelapse_raw)\n",
    "tifffile.imwrite(f\"{temporary_output_dir}/detections.tif\", detections)\n",
    "tifffile.imwrite(f\"{temporary_output_dir}/edges.tif\", edges)\n",
    "\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = estimate_parameters_from_labels(stardist_labels, is_timelapse=True)\n",
    "if in_notebook:\n",
    "    params_df[\"area\"].plot(kind=\"hist\", bins=100, title=\"Area histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MainConfig()\n",
    "config.segmentation_config.min_area = 30\n",
    "config.segmentation_config.max_area = 1250\n",
    "config.segmentation_config.n_workers = 8\n",
    "config.segmentation_config.threshold = 0.7\n",
    "config.linking_config.max_distance = 45\n",
    "config.linking_config.n_workers = 8\n",
    "\n",
    "config.tracking_config.appear_weight = -1\n",
    "config.tracking_config.disappear_weight = -0.5\n",
    "config.tracking_config.division_weight = -0.1\n",
    "config.tracking_config.power = 4\n",
    "config.tracking_config.bias = -0.001\n",
    "config.tracking_config.solution_gap = 0.0\n",
    "# config.tracking_config.solver_name = \"CBC\"\n",
    "pprint(config.dict())\n",
    "# write the config to a file for reference later\n",
    "with open(f\"{results_output_dir}/config.json\", \"w\") as f:\n",
    "    f.write(config.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track(\n",
    "    foreground=detections,\n",
    "    edges=edges,\n",
    "    config=config,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df, graph = to_tracks_layer(config)\n",
    "labels = tracks_to_zarr(config, tracks_df)\n",
    "tracks_df.to_parquet(\n",
    "    f\"{results_output_dir}/{str(input_dir_main).split('MaxIP_')[1]}_tracks.parquet\"\n",
    ")\n",
    "print(tracks_df[\"track_id\"].nunique())\n",
    "print(\n",
    "    f\"There {max_number_of_objects} expected tracks; found {tracks_df['track_id'].nunique()}\"\n",
    ")\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tracks as parquet\n",
    "tracks_df.reset_index(drop=True, inplace=True)\n",
    "tracks = np.zeros((len(tiff_files), image_dims[0], image_dims[1]), dtype=np.uint16)\n",
    "cum_tracks_df = tracks_df.copy()\n",
    "timepoints = tracks_df[\"t\"].unique()\n",
    "\n",
    "# zero out the track_df\n",
    "cum_tracks_df = cum_tracks_df.loc[cum_tracks_df[\"t\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_notebook:\n",
    "    for frame_index, _ in enumerate(timelapse_raw):\n",
    "        tmp_df = tracks_df.loc[tracks_df[\"t\"] == frame_index]\n",
    "        cum_tracks_df = pd.concat([cum_tracks_df, tmp_df])\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.subplot(2, 3, 1)\n",
    "        # rescale tbe intensity of the raw image\n",
    "        raw_image = timelapse_raw_visualize[frame_index, :, :]\n",
    "        raw_image = raw_image * 4096\n",
    "        plt.imshow(raw_image, cmap=\"gray\")\n",
    "        plt.title(\"Raw\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.imshow(stardist_labels[frame_index, :, :], cmap=\"gray\")\n",
    "        plt.title(\"Masks\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 3, 3)\n",
    "        sns.lineplot(data=cum_tracks_df, x=\"x\", y=\"y\", hue=\"track_id\", legend=False)\n",
    "        plt.imshow(labels[frame_index, :, :], cmap=\"gray\", alpha=0.5)\n",
    "        plt.title(f\"Frame {frame_index}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 3, 4)\n",
    "        edge_image = skimage.exposure.adjust_gamma(\n",
    "            edges[frame_index, :, :], gamma=0.0001\n",
    "        )\n",
    "        # make the outline brighter\n",
    "        edge_image = edge_image * 1000\n",
    "        plt.imshow(edge_image, cmap=\"gray\")\n",
    "        plt.title(\"Edges\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.imshow(detections[frame_index, :, :], cmap=\"gray\")\n",
    "        plt.title(\"Detections\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 3, 6)\n",
    "        sns.lineplot(data=cum_tracks_df, x=\"x\", y=\"y\", hue=\"track_id\", legend=False)\n",
    "        plt.imshow(detections[frame_index, :, :], cmap=\"gray\", alpha=0.5)\n",
    "        plt.title(f\"Frame {frame_index}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{temporary_output_dir}/tracks_{frame_index}.png\")\n",
    "    if in_notebook:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each image\n",
    "files = [f for f in temporary_output_dir.glob(\"*.png\")]\n",
    "files = sorted(files, key=lambda x: int(x.stem.split(\"_\")[1]))\n",
    "frames = [Image.open(f) for f in files]\n",
    "fig_path = figures_output_dir / f\"{str(input_dir_main).split('MaxIP_')[1]}_tracks.gif\"\n",
    "# plot the line of each track in matplotlib over a gif\n",
    "# get the tracks\n",
    "# save the frames as a gif\n",
    "frames[0].save(fig_path, save_all=True, append_images=frames[1:], duration=3, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up tracking files\n",
    "# remvoe temporary_output_dir\n",
    "shutil.rmtree(temporary_output_dir)\n",
    "\n",
    "track_db_path = pathlib.Path(\"data.db\").resolve()\n",
    "metadata_toml_path = pathlib.Path(\"metadata.toml\").resolve()\n",
    "if track_db_path.exists():\n",
    "    track_db_path.unlink()\n",
    "if metadata_toml_path.exists():\n",
    "    metadata_toml_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_gpu_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_segmentation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
