{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs stardist 2D.\n",
    "This is to establish a segmentation ground truth for the data.\n",
    "This methods does not track cells though however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 20:54:45.252040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 20:54:45.264896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 20:54:45.267975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 20:54:45.275711: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "import argparse\n",
    "import gc  # garbage collector\n",
    "import logging  # logging\n",
    "import pathlib  # path handling\n",
    "import shutil  # file handling\n",
    "import subprocess  # subprocess handling\n",
    "import sys  # system\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np  # numerical python\n",
    "import pandas as pd  # data handling\n",
    "import pyarrow as pa  # pyarrow for parquet\n",
    "import tqdm  # progress bar\n",
    "from csbdeep.utils import Path, normalize  # dependecy for stardist\n",
    "from PIL import Image  # image handling\n",
    "from skimage import io  # image handling\n",
    "from skimage.measure import label, regionprops  # coordinate handling\n",
    "from skimage.transform import resize  # image handling\n",
    "from stardist.models import StarDist2D  # stardist\n",
    "from stardist.plot import render_label  # stardist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the arguments\n",
    "# parser = argparse.ArgumentParser(description=\"Process timelapse images.\")\n",
    "# parser.add_argument(\n",
    "#     \"--downscale_factor\", type=int, default=1, help=\"Downsample factor for images\"\n",
    "# )\n",
    "\n",
    "# # get the arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# downscale_factor = args.downscale_factor\n",
    "\n",
    "\n",
    "downscale_factor = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the videos\n",
    "stardist_processing_dir = pathlib.Path(\n",
    "    f\"../stardist_processing_dir/{downscale_factor}x_factor/\"\n",
    ").resolve()\n",
    "\n",
    "tiff_dir = pathlib.Path(\n",
    "    \"../../2.cellprofiler_ic_processing/illum_directory/timelapse/\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "stardist_processing_dir.mkdir(parents=True, exist_ok=True)\n",
    "ordered_tiffs = pathlib.Path(stardist_processing_dir / \"tiffs/\").resolve()\n",
    "converted_to_video_dir = pathlib.Path(stardist_processing_dir / \"jpegs/\").resolve()\n",
    "if converted_to_video_dir.exists():\n",
    "    shutil.rmtree(converted_to_video_dir)\n",
    "\n",
    "ordered_tiffs.mkdir(parents=True, exist_ok=True)\n",
    "converted_to_video_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data formatted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560 prior to removing F0005 and F0006\n",
      "1560 after removing F0005 and F0006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>Well</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Z-slice</th>\n",
       "      <th>Well_FOV</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D-02_F0003_T0006_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-02</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0006</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-02_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D-02_F0003_T0013_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-02</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0013</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-02_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D-02_F0003_T0007_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-02</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0007</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-02_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D-02_F0003_T0009_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-02</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0009</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-02_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D-02_F0003_T0001_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-02</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0001</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-02_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  \\\n",
       "0  D-02_F0003_T0006_Z0001_C01_illumcorrect   \n",
       "1  D-02_F0003_T0013_Z0001_C01_illumcorrect   \n",
       "2  D-02_F0003_T0007_Z0001_C01_illumcorrect   \n",
       "3  D-02_F0003_T0009_Z0001_C01_illumcorrect   \n",
       "4  D-02_F0003_T0001_Z0001_C01_illumcorrect   \n",
       "\n",
       "                                           file_path  Well    FOV Timepoint  \\\n",
       "0  /home/lippincm/Documents/live_cell_timelapse_a...  D-02  F0003     T0006   \n",
       "1  /home/lippincm/Documents/live_cell_timelapse_a...  D-02  F0003     T0013   \n",
       "2  /home/lippincm/Documents/live_cell_timelapse_a...  D-02  F0003     T0007   \n",
       "3  /home/lippincm/Documents/live_cell_timelapse_a...  D-02  F0003     T0009   \n",
       "4  /home/lippincm/Documents/live_cell_timelapse_a...  D-02  F0003     T0001   \n",
       "\n",
       "  Z-slice    Well_FOV                                           new_path  \n",
       "0   Z0001  D-02_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "1   Z0001  D-02_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "2   Z0001  D-02_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "3   Z0001  D-02_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "4   Z0001  D-02_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of tiff files in the directory\n",
    "tiff_files = list(tiff_dir.rglob(\"*.tiff\"))\n",
    "tiff_file_names = [file.stem for file in tiff_files]\n",
    "# files to df\n",
    "tiff_df = pd.DataFrame({\"file_name\": tiff_file_names, \"file_path\": tiff_files})\n",
    "\n",
    "# split the file_path column by _ but keep the original column\n",
    "tiff_df[\"file_name\"] = tiff_df[\"file_name\"].astype(str)\n",
    "tiff_df[[\"Well\", \"FOV\", \"Timepoint\", \"Z-slice\", \"Channel\", \"illum\"]] = tiff_df[\n",
    "    \"file_name\"\n",
    "].str.split(\"_\", expand=True)\n",
    "tiff_df[\"Well_FOV\"] = tiff_df[\"Well\"] + \"_\" + tiff_df[\"FOV\"]\n",
    "# drop all channels except for the first one\n",
    "tiff_df = tiff_df[tiff_df[\"Channel\"] == \"C01\"]\n",
    "tiff_df = tiff_df.drop(columns=[\"Channel\", \"illum\"])\n",
    "tiff_df[\"new_path\"] = (\n",
    "    str(ordered_tiffs)\n",
    "    + \"/\"\n",
    "    + tiff_df[\"Well_FOV\"]\n",
    "    + \"/\"\n",
    "    + tiff_df[\"file_name\"]\n",
    "    + \".tiff\"\n",
    ")\n",
    "# remove any file name that contain \"F0005\" or \"F0006\"\n",
    "print(f\"{tiff_df.shape[0]} prior to removing F0005 and F0006\")\n",
    "tiff_df = tiff_df[~tiff_df[\"file_name\"].str.contains(\"F0005\")]\n",
    "tiff_df = tiff_df[~tiff_df[\"file_name\"].str.contains(\"F0006\")]\n",
    "tiff_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"{tiff_df.shape[0]} after removing F0005 and F0006\")\n",
    "tiff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the files to the new directory\n",
    "# from file path to new path\n",
    "for index, row in tiff_df.iterrows():\n",
    "    new_path = pathlib.Path(row[\"new_path\"])\n",
    "    new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(row[\"file_path\"], new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of directories in the ordered tiffs directory\n",
    "ordered_tiff_dirs = list(ordered_tiffs.glob(\"*\"))\n",
    "ordered_tiff_dir_names = [dir for dir in ordered_tiff_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in ordered_tiff_dir_names:\n",
    "    out_dir = converted_to_video_dir / dir.name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for tiff_file in dir.glob(\"*.tiff\"):\n",
    "        jpeg_file = pathlib.Path(f\"{out_dir}/{tiff_file.stem}.jpeg\")\n",
    "\n",
    "        if not jpeg_file.exists():\n",
    "            try:\n",
    "                with Image.open(tiff_file) as img:\n",
    "                    # Convert the image to 8-bit per channel\n",
    "                    img = img.convert(\"L\")\n",
    "                    img.save(jpeg_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {tiff_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of dirs in the converted to video dir\n",
    "converted_dirs = list(converted_to_video_dir.glob(\"*\"))\n",
    "converted_dir_names = [dir for dir in converted_dirs]\n",
    "for dir in converted_dir_names:\n",
    "    dir = sorted(dir.glob(\"*.jpeg\"))\n",
    "    for i in enumerate(dir):\n",
    "        # rename the files to be in order\n",
    "        i[1].rename(f\"{dir[0].parent}/{str(i[0] + 1).zfill(3)}.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donwsample each frame to fit the images on the GPU - overwrite the copies JPEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files in the directory\n",
    "converted_dirs_list = list(converted_to_video_dir.rglob(\"*\"))\n",
    "converted_dirs_list = [f for f in converted_dirs_list if f.is_file()]\n",
    "# posix path to string\n",
    "files = [str(f) for f in converted_dirs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to downscale to fit the model and images on the GPU\n",
    "# note that this is an arbitrary number and can be changed\n",
    "# sort the files by name\n",
    "# downsample the image\n",
    "for f in files:\n",
    "    img = io.imread(f)\n",
    "    # downsample the image\n",
    "    downsampled_img = img[::downscale_factor, ::downscale_factor]\n",
    "    # save the downsampled image in place of the original image\n",
    "    io.imsave(f, downsampled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the stardist ground truth for each frame and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where one image set here is a single well and fov over all timepoints\n",
    "all_images_set_dict = {\n",
    "    \"image_set_name\": [],  # e.g. well_fov\n",
    "    \"image_set_path\": [],  # path to the directory\n",
    "    \"images\": [],  # path to the first frame\n",
    "    \"number_of_objects\": [],  # list of x,y coordinates\n",
    "}\n",
    "\n",
    "# get the list of directories in the ordered tiffs directory\n",
    "dirs = list(converted_to_video_dir.glob(\"*\"))\n",
    "dirs = [dir for dir in dirs if dir.is_dir()]\n",
    "dirs = sorted(dirs)\n",
    "for dir in dirs:\n",
    "    # get the files in the directory\n",
    "    files = sorted(dir.glob(\"*.jpeg\"))\n",
    "    all_images_set_dict[\"image_set_name\"].append(dir.name)\n",
    "    all_images_set_dict[\"image_set_path\"].append(str(dir))\n",
    "    all_images_set_dict[\"images\"].append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741661745.323483 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.451974 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.455233 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.459392 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.464444 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.467256 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.582907 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.584093 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741661745.585219 1232031 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 20:55:45.586310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20605 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]functional.py (225): The structure of `inputs` doesn't match the expected structure: ['input']. Received: the structure of inputs=*\n",
      "I0000 00:00:1741661746.588063 1232569 service.cc:146] XLA service 0x7337480051a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741661746.588086 1232569 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2025-03-10 20:55:46.602440: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-10 20:55:46.666110: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "I0000 00:00:1741661747.436152 1232569 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "100%|██████████| 120/120 [03:43<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
    "\n",
    "for i in tqdm.tqdm(range(len(all_images_set_dict[\"image_set_name\"]))):\n",
    "    for image in enumerate(all_images_set_dict[\"images\"][i][:3]):\n",
    "        img = io.imread(image[1])\n",
    "        labels, _ = model.predict_instances(normalize(img))\n",
    "\n",
    "        # convert the labels into position coordinates\n",
    "        regions = regionprops(label(labels))\n",
    "        coords = np.array([r.centroid for r in regions])\n",
    "        # save the coordinates to a file in the image set directory\n",
    "        coords_path = pathlib.Path(\n",
    "            f\"{str(stardist_processing_dir)}/star_dist_coords/{all_images_set_dict['image_set_name'][i]}/\"\n",
    "        ).resolve()\n",
    "        coords_path.mkdir(parents=True, exist_ok=True)\n",
    "        coords_path = (\n",
    "            coords_path\n",
    "            / f\"{all_images_set_dict['images'][i][image[0]].stem}_coords.parquet\"\n",
    "        )\n",
    "        coords_df = pd.DataFrame(coords, columns=[\"y\", \"x\"])\n",
    "        # rescale the coordinates to the original image size\n",
    "        # coords_df[\"x\"] = coords_df[\"x\"] * downscale_factor\n",
    "        # coords_df[\"y\"] = coords_df[\"y\"] * downscale_factor\n",
    "        coords_df.to_parquet(coords_path)\n",
    "        # save the mask image generated by stardist\n",
    "        mask = render_label(labels, img=img)\n",
    "        all_images_set_dict[\"number_of_objects\"].append(len(coords))\n",
    "        # upscale the mask using the downscale factor\n",
    "        # mask = resize(\n",
    "        #     mask, (mask.shape[0] * downscale_factor, mask.shape[1] * downscale_factor)\n",
    "        # )\n",
    "        # save the mask\n",
    "        mask_path = pathlib.Path(\n",
    "            f\"{str(stardist_processing_dir)}/star_dist_masks/{all_images_set_dict['image_set_name'][i]}/\"\n",
    "        ).resolve()\n",
    "        mask_path.mkdir(parents=True, exist_ok=True)\n",
    "        mask_path = (\n",
    "            mask_path / f\"{all_images_set_dict['images'][i][image[0]].stem}.jpeg\"\n",
    "        )\n",
    "        plt.imsave(mask_path, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stardist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
