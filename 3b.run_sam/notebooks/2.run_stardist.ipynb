{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs stardist 2D.\n",
    "This is to establish a segmentation ground truth for the data.\n",
    "This methods does not track cells though however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 10:33:43.292301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-01 10:33:43.303906: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-01 10:33:43.307430: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-01 10:33:43.317113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-01 10:33:43.928013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "import argparse\n",
    "import gc  # garbage collector\n",
    "import logging  # logging\n",
    "import pathlib  # path handling\n",
    "import shutil  # file handling\n",
    "import subprocess  # subprocess handling\n",
    "import sys  # system\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np  # numerical python\n",
    "import pandas as pd  # data handling\n",
    "import pyarrow as pa  # pyarrow for parquet\n",
    "import torch  # pytorch deep learning\n",
    "import tqdm  # progress bar\n",
    "from csbdeep.utils import Path, normalize  # dependecy for stardist\n",
    "from PIL import Image  # image handling\n",
    "from skimage import io  # image handling\n",
    "from skimage.measure import label, regionprops  # coordinate handling\n",
    "from skimage.transform import resize  # image handling\n",
    "from stardist.models import StarDist2D  # stardist\n",
    "from stardist.plot import render_label  # stardist\n",
    "from torchvision import models  # pytorch models\n",
    "\n",
    "# check cuda devices\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the arguments\n",
    "# parser = argparse.ArgumentParser(description=\"Process timelapse images.\")\n",
    "# parser.add_argument(\n",
    "#     \"--downscale_factor\", type=int, default=1, help=\"Downsample factor for images\"\n",
    "# )\n",
    "\n",
    "# # get the arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# downscale_factor = args.downscale_factor\n",
    "\n",
    "\n",
    "downscale_factor = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the videos\n",
    "stardist_processing_dir = pathlib.Path(\n",
    "    f\"../stardist_processing_dir/{downscale_factor}x_factor/\"\n",
    ").resolve()\n",
    "\n",
    "tiff_dir = pathlib.Path(\n",
    "    \"../../2.cellprofiler_ic_processing/illum_directory/20231017ChromaLive_6hr_4ch_MaxIP/\"\n",
    ").resolve(strict=True)\n",
    "terminal_dir = pathlib.Path(\n",
    "    \"../../2.cellprofiler_ic_processing/illum_directory/20231017ChromaLive_endpoint_w_AnnexinV_2ch_MaxIP/\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "stardist_processing_dir.mkdir(parents=True, exist_ok=True)\n",
    "ordered_tiffs = pathlib.Path(stardist_processing_dir / \"tiffs/\").resolve()\n",
    "converted_to_video_dir = pathlib.Path(stardist_processing_dir / \"pngs/\").resolve()\n",
    "if converted_to_video_dir.exists():\n",
    "    shutil.rmtree(converted_to_video_dir)\n",
    "\n",
    "ordered_tiffs.mkdir(parents=True, exist_ok=True)\n",
    "converted_to_video_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data formatted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740 prior to removing F0005 and F0006\n",
      "1680 after removing F0005 and F0006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>Well</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Z-slice</th>\n",
       "      <th>Well_FOV</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E-06_F0003_T0005_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>E-06</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0005</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>E-06_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-02_F0002_T0006_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>C-02</td>\n",
       "      <td>F0002</td>\n",
       "      <td>T0006</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>C-02_F0002</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-07_F0002_T0004_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>C-07</td>\n",
       "      <td>F0002</td>\n",
       "      <td>T0004</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>C-07_F0002</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D-11_F0003_T0009_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>D-11</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0009</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>D-11_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-09_F0003_T0002_Z0001_C01_illumcorrect</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "      <td>E-09</td>\n",
       "      <td>F0003</td>\n",
       "      <td>T0002</td>\n",
       "      <td>Z0001</td>\n",
       "      <td>E-09_F0003</td>\n",
       "      <td>/home/lippincm/Documents/live_cell_timelapse_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  \\\n",
       "0  E-06_F0003_T0005_Z0001_C01_illumcorrect   \n",
       "1  C-02_F0002_T0006_Z0001_C01_illumcorrect   \n",
       "2  C-07_F0002_T0004_Z0001_C01_illumcorrect   \n",
       "3  D-11_F0003_T0009_Z0001_C01_illumcorrect   \n",
       "4  E-09_F0003_T0002_Z0001_C01_illumcorrect   \n",
       "\n",
       "                                           file_path  Well    FOV Timepoint  \\\n",
       "0  /home/lippincm/Documents/live_cell_timelapse_a...  E-06  F0003     T0005   \n",
       "1  /home/lippincm/Documents/live_cell_timelapse_a...  C-02  F0002     T0006   \n",
       "2  /home/lippincm/Documents/live_cell_timelapse_a...  C-07  F0002     T0004   \n",
       "3  /home/lippincm/Documents/live_cell_timelapse_a...  D-11  F0003     T0009   \n",
       "4  /home/lippincm/Documents/live_cell_timelapse_a...  E-09  F0003     T0002   \n",
       "\n",
       "  Z-slice    Well_FOV                                           new_path  \n",
       "0   Z0001  E-06_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "1   Z0001  C-02_F0002  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "2   Z0001  C-07_F0002  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "3   Z0001  D-11_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  \n",
       "4   Z0001  E-09_F0003  /home/lippincm/Documents/live_cell_timelapse_a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of tiff files in the directory\n",
    "tiff_files = list(tiff_dir.glob(\"*.tiff\"))\n",
    "tiff_files = tiff_files + list(terminal_dir.glob(\"*.tiff\"))\n",
    "tiff_file_names = [file.stem for file in tiff_files]\n",
    "# files to df\n",
    "tiff_df = pd.DataFrame({\"file_name\": tiff_file_names, \"file_path\": tiff_files})\n",
    "\n",
    "# split the file_path column by _ but keep the original column\n",
    "tiff_df[\"file_name\"] = tiff_df[\"file_name\"].astype(str)\n",
    "tiff_df[[\"Well\", \"FOV\", \"Timepoint\", \"Z-slice\", \"Channel\", \"illum\"]] = tiff_df[\n",
    "    \"file_name\"\n",
    "].str.split(\"_\", expand=True)\n",
    "tiff_df[\"Well_FOV\"] = tiff_df[\"Well\"] + \"_\" + tiff_df[\"FOV\"]\n",
    "# drop all channels except for the first one\n",
    "tiff_df = tiff_df[tiff_df[\"Channel\"] == \"C01\"]\n",
    "tiff_df = tiff_df.drop(columns=[\"Channel\", \"illum\"])\n",
    "tiff_df[\"new_path\"] = (\n",
    "    str(ordered_tiffs)\n",
    "    + \"/\"\n",
    "    + tiff_df[\"Well_FOV\"]\n",
    "    + \"/\"\n",
    "    + tiff_df[\"file_name\"]\n",
    "    + \".tiff\"\n",
    ")\n",
    "# remove any file name that contain \"F0005\" or \"F0006\"\n",
    "print(f\"{tiff_df.shape[0]} prior to removing F0005 and F0006\")\n",
    "tiff_df = tiff_df[~tiff_df[\"file_name\"].str.contains(\"F0005\")]\n",
    "tiff_df = tiff_df[~tiff_df[\"file_name\"].str.contains(\"F0006\")]\n",
    "tiff_df.reset_index(drop=True, inplace=True)\n",
    "print(f\"{tiff_df.shape[0]} after removing F0005 and F0006\")\n",
    "tiff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the files to the new directory\n",
    "# from file path to new path\n",
    "for index, row in tiff_df.iterrows():\n",
    "    new_path = pathlib.Path(row[\"new_path\"])\n",
    "    new_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy(row[\"file_path\"], new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of directories in the ordered tiffs directory\n",
    "ordered_tiff_dirs = list(ordered_tiffs.glob(\"*\"))\n",
    "ordered_tiff_dir_names = [dir for dir in ordered_tiff_dirs]\n",
    "ordered_tiff_dir_names\n",
    "for dir in ordered_tiff_dir_names:\n",
    "    out_dir = converted_to_video_dir / dir.name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for tiff_file in dir.glob(\"*.tiff\"):\n",
    "        jpeg_file = pathlib.Path(f\"{out_dir}/{tiff_file.stem}.jpeg\")\n",
    "\n",
    "        if not jpeg_file.exists():\n",
    "            try:\n",
    "                with Image.open(tiff_file) as img:\n",
    "                    # Convert the image to 8-bit per channel\n",
    "                    img = img.convert(\"L\")\n",
    "                    img.save(jpeg_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {tiff_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of dirs in the converted to video dir\n",
    "converted_dirs = list(converted_to_video_dir.glob(\"*\"))\n",
    "converted_dir_names = [dir for dir in converted_dirs]\n",
    "for dir in converted_dir_names:\n",
    "    dir = sorted(dir.glob(\"*.jpeg\"))\n",
    "    for i in enumerate(dir):\n",
    "        # rename the files to be in order\n",
    "        i[1].rename(f\"{dir[0].parent}/{str(i[0] + 1).zfill(3)}.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donwsample each frame to fit the images on the GPU - overwrite the copies JPEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files in the directory\n",
    "converted_dirs_list = list(converted_to_video_dir.rglob(\"*\"))\n",
    "converted_dirs_list = [f for f in converted_dirs_list if f.is_file()]\n",
    "# posix path to string\n",
    "files = [str(f) for f in converted_dirs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to downscale to fit the model and images on the GPU\n",
    "# note that this is an arbitrary number and can be changed\n",
    "# sort the files by name\n",
    "# downsample the image\n",
    "for f in files:\n",
    "    img = io.imread(f)\n",
    "    # downsample the image\n",
    "    downsampled_img = img[::downscale_factor, ::downscale_factor]\n",
    "    # save the downsampled image in place of the original image\n",
    "    io.imsave(f, downsampled_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the stardist ground truth for each frame and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where one image set here is a single well and fov over all timepoints\n",
    "all_images_set_dict = {\n",
    "    \"image_set_name\": [],  # e.g. well_fov\n",
    "    \"image_set_path\": [],  # path to the directory\n",
    "    \"images\": [],  # path to the first frame\n",
    "    \"number_of_objects\": [],  # list of x,y coordinates\n",
    "}\n",
    "\n",
    "# get the list of directories in the ordered tiffs directory\n",
    "dirs = list(converted_to_video_dir.glob(\"*\"))\n",
    "dirs = [dir for dir in dirs if dir.is_dir()]\n",
    "for dir in dirs:\n",
    "    # get the files in the directory\n",
    "    files = sorted(dir.glob(\"*.jpeg\"))\n",
    "    all_images_set_dict[\"image_set_name\"].append(dir.name)\n",
    "    all_images_set_dict[\"image_set_path\"].append(str(dir))\n",
    "    all_images_set_dict[\"images\"].append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730478892.880200 1736463 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-01 10:34:52.886505: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 10/120 [02:31<27:48, 15.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m all_images_set_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(coords))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# upscale the mask using the downscale factor\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m mask \u001b[38;5;241m=\u001b[39m resize(mask, (mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m downscale_factor, mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m downscale_factor))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# save the mask\u001b[39;00m\n\u001b[1;32m     17\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(stardist_processing_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/star_dist_masks/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_images_set_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_set_name\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\n",
      "File \u001b[0;32m~/miniforge3/envs/sam2_env/lib/python3.12/site-packages/skimage/transform/_warps.py:203\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    200\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m    202\u001b[0m zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n\u001b[0;32m--> 203\u001b[0m out \u001b[38;5;241m=\u001b[39m ndi\u001b[38;5;241m.\u001b[39mzoom(\n\u001b[1;32m    204\u001b[0m     filtered, zoom_factors, order\u001b[38;5;241m=\u001b[39morder, mode\u001b[38;5;241m=\u001b[39mndi_mode, cval\u001b[38;5;241m=\u001b[39mcval, grid_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m _clip_warp_output(image, out, mode, cval, clip)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/sam2_env/lib/python3.12/site-packages/scipy/ndimage/_interpolation.py:869\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    865\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    866\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    867\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    868\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 869\u001b[0m _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, zoom, \u001b[38;5;28;01mNone\u001b[39;00m, output, order, mode, cval, npad,\n\u001b[1;32m    870\u001b[0m                      grid_mode)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
    "\n",
    "for i in tqdm.tqdm(range(len(all_images_set_dict[\"image_set_name\"]))):\n",
    "    for image in enumerate(all_images_set_dict[\"images\"][i]):\n",
    "        img = io.imread(image[1])\n",
    "        labels, _ = model.predict_instances(normalize(img))\n",
    "\n",
    "        # convert the labels into position coordinates\n",
    "        regions = regionprops(label(labels))\n",
    "        coords = np.array([r.centroid for r in regions])\n",
    "        # save the mask image generated by stardist\n",
    "        mask = render_label(labels, img=img)\n",
    "        all_images_set_dict[\"number_of_objects\"].append(len(coords))\n",
    "        # upscale the mask using the downscale factor\n",
    "        mask = resize(\n",
    "            mask, (mask.shape[0] * downscale_factor, mask.shape[1] * downscale_factor)\n",
    "        )\n",
    "        # save the mask\n",
    "        mask_path = pathlib.Path(\n",
    "            f\"{str(stardist_processing_dir)}/star_dist_masks/{all_images_set_dict['image_set_name'][i]}/\"\n",
    "        ).resolve()\n",
    "        mask_path.mkdir(parents=True, exist_ok=True)\n",
    "        mask_path = (\n",
    "            mask_path / f\"{all_images_set_dict['images'][i][image[0]].stem}_mask.png\"\n",
    "        )\n",
    "        plt.imsave(mask_path, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
