{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate merged single cells with metadata from platemap file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lippincm/miniforge3/envs/cellprofiler_timelapse_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import lancedb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pycytominer import annotate\n",
    "from pycytominer.cyto_utils import output\n",
    "\n",
    "try:\n",
    "    cfg = get_ipython().config\n",
    "    in_notebook = True\n",
    "except NameError:\n",
    "    in_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_coordinate_fuzzy_match(\n",
    "    df_left: pd.DataFrame,\n",
    "    df_right: pd.DataFrame,\n",
    "    left_on: list,\n",
    "    right_on: list,\n",
    "    coordinate_column: str,\n",
    "    unique_image_column: str,\n",
    "    pixel_cutt_off: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function fuzzy merges two dataframes based on the euclidean distance between the coordinates in the coordinate_column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_left : pd.DataFrame\n",
    "        left dataframe to merge\n",
    "    df_right : pd.DataFrame\n",
    "        right dataframe to merge\n",
    "    left_on : list\n",
    "        Left dataframe columns to match on\n",
    "    right_on : list\n",
    "        Right dataframe columns to match on\n",
    "    coordinate_column : str\n",
    "        The column name that contains the coordinates to match on\n",
    "        Note that the coordinates should be in a tuple format\n",
    "    unique_image_column : str\n",
    "        The column name that contains the unique image identifier to split the dataframes on\n",
    "        This ensures that coordinates from other images are not matched together\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A merged dataframe of the two input dataframes based on the euclidean distance between the coordinates\n",
    "    \"\"\"\n",
    "    # split each data frame into each cell_merge_column\n",
    "    all_images = df_left[unique_image_column].unique()\n",
    "\n",
    "    merged_df_list = []  # list to store the merged dataframes\n",
    "    total_CP_cells = 0  # total number of cells in the left dataframe\n",
    "    total_annotated_cells = 0  # total number of cells that were annotated\n",
    "    distances = []  # list to store the distances between the coordinates\n",
    "\n",
    "    for image in all_images:\n",
    "        subset_df_left = df_left[df_left[unique_image_column] == image]\n",
    "        subset_df_right = df_right[df_right[unique_image_column] == image]\n",
    "        total_CP_cells += subset_df_left.shape[0]\n",
    "        # loop through the rows in the subset_annotated_df and find the closest coordinate set in the location metadata\n",
    "        for index1, row1 in subset_df_left.iterrows():\n",
    "            dist = np.inf\n",
    "            for index2, row2 in subset_df_right.iterrows():\n",
    "                coord1 = row1[coordinate_column]\n",
    "                coord2 = row2[coordinate_column]\n",
    "                try:\n",
    "                    temp_dist = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "                except:\n",
    "                    temp_dist = np.inf\n",
    "                if temp_dist <= dist:\n",
    "                    dist = temp_dist\n",
    "                    coord2_index = index2\n",
    "\n",
    "            # set cut off of 5,5 pixel in the euclidean distance\n",
    "            euclidean_cut_off = np.linalg.norm(\n",
    "                np.array([0, 0]) - np.array([pixel_cutt_off, pixel_cutt_off])\n",
    "            )\n",
    "\n",
    "            if dist < np.inf:\n",
    "                temp_merged_df = pd.merge(\n",
    "                    subset_df_left.loc[[index1]],\n",
    "                    subset_df_right.loc[[coord2_index]],\n",
    "                    how=\"inner\",\n",
    "                    left_on=right_on,\n",
    "                    right_on=left_on,\n",
    "                )\n",
    "                distances.append(dist)\n",
    "                total_annotated_cells += temp_merged_df.shape[0]\n",
    "                merged_df_list.append(temp_merged_df)\n",
    "    if len(merged_df_list) == 0:\n",
    "        return pd.DataFrame()\n",
    "    merged_df = pd.concat(merged_df_list)\n",
    "    merged_df[\"distance\"] = distances\n",
    "    print(f\"Percentage of annotated cells: {total_annotated_cells/total_CP_cells*100}%\")\n",
    "    return merged_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a notebook\n"
     ]
    }
   ],
   "source": [
    "# load in platemap file as a pandas dataframe\n",
    "platemap_path = pathlib.Path(\"../../data/\").resolve()\n",
    "\n",
    "# directory where parquet files are located\n",
    "data_dir = pathlib.Path(\"../data/converted_data\").resolve()\n",
    "\n",
    "# directory where the annotated parquet files are saved to\n",
    "output_dir = pathlib.Path(\"../data/annotated_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if not in_notebook:\n",
    "    print(\"Running as script\")\n",
    "    # set up arg parser\n",
    "    parser = argparse.ArgumentParser(description=\"Single cell extraction\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--well_fov\",\n",
    "        type=str,\n",
    "        help=\"Path to the input directory containing the tiff images\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    well_fov = args.well_fov\n",
    "    images_dir = pathlib.Path(data_dir / well_fov).resolve(strict=True)\n",
    "else:\n",
    "    print(\"Running in a notebook\")\n",
    "    well_fov = \"C-02_F0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with each run for the cell type\n",
    "dict_of_inputs = {\n",
    "    \"run_20231017ChromaLive_6hr_4ch_MaxIP\": {\n",
    "        \"source_path\": pathlib.Path(f\"{data_dir}/timelapse/{well_fov}.parquet\").resolve(\n",
    "            strict=True\n",
    "        ),\n",
    "        \"platemap_path\": pathlib.Path(f\"{platemap_path}/platemap_6hr_4ch.csv\").resolve(\n",
    "            strict=True\n",
    "        ),\n",
    "        \"output_file\": pathlib.Path(\n",
    "            f\"{output_dir}/timelapse/{well_fov}_sc.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "    \"20231017ChromaLive_endpoint_w_AnnexinV_2ch_MaxIP\": {\n",
    "        \"source_path\": pathlib.Path(f\"{data_dir}/endpoint/{well_fov}.parquet\").resolve(\n",
    "            strict=True\n",
    "        ),\n",
    "        \"platemap_path\": pathlib.Path(\n",
    "            f\"{platemap_path}/platemap_AnnexinV_2ch.csv\"\n",
    "        ).resolve(strict=True),\n",
    "        \"output_file\": pathlib.Path(\n",
    "            f\"{output_dir}/endpoint/{well_fov}_sc.parquet\"\n",
    "        ).resolve(),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate merged single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2309, 2318)\n",
      "Adding annotations to merged single cells for run_20231017ChromaLive_6hr_4ch_MaxIP!\n",
      "(2309, 2322)\n",
      "Annotations have been added to run_20231017ChromaLive_6hr_4ch_MaxIP and saved to /home/lippincm/Documents/live_cell_timelapse_apoptosis/5.process_CP_features/data/annotated_data/timelapse/C-02_F0001_sc.parquet\n",
      "(2309, 2322)\n",
      "(155, 1202)\n",
      "Adding annotations to merged single cells for 20231017ChromaLive_endpoint_w_AnnexinV_2ch_MaxIP!\n",
      "(1860, 1206)\n",
      "Annotations have been added to 20231017ChromaLive_endpoint_w_AnnexinV_2ch_MaxIP and saved to /home/lippincm/Documents/live_cell_timelapse_apoptosis/5.process_CP_features/data/annotated_data/endpoint/C-02_F0001_sc.parquet\n",
      "(1860, 1206)\n"
     ]
    }
   ],
   "source": [
    "for data_run, info in dict_of_inputs.items():\n",
    "    # load in converted parquet file as df to use in annotate function\n",
    "    single_cell_df = pd.read_parquet(info[\"source_path\"])\n",
    "    print(single_cell_df.shape)\n",
    "    single_cell_df = single_cell_df.rename(\n",
    "        columns={\n",
    "            \"Image_Metadata_FOV\": \"Metadata_FOV\",\n",
    "            \"Image_Metadata_Time\": \"Metadata_Time\",\n",
    "        },\n",
    "    )\n",
    "    platemap_df = pd.read_csv(info[\"platemap_path\"])\n",
    "\n",
    "    print(f\"Adding annotations to merged single cells for {data_run}!\")\n",
    "\n",
    "    # add metadata from platemap file to extracted single cell features\n",
    "    annotated_df = annotate(\n",
    "        profiles=single_cell_df,\n",
    "        platemap=platemap_df,\n",
    "        join_on=[\"Metadata_well\", \"Image_Metadata_Well\"],\n",
    "    )\n",
    "    print(annotated_df.shape)\n",
    "\n",
    "    # move metadata well and single cell count to the front of the df (for easy visualization in python)\n",
    "    well_column = annotated_df.pop(\"Metadata_Well\")\n",
    "    singlecell_column = annotated_df.pop(\"Metadata_number_of_singlecells\")\n",
    "    # insert the column as the second index column in the dataframe\n",
    "    annotated_df.insert(1, \"Metadata_Well\", well_column)\n",
    "    annotated_df.insert(2, \"Metadata_number_of_singlecells\", singlecell_column)\n",
    "\n",
    "    # rename metadata columns to match the expected column names\n",
    "    columns_to_rename = {\n",
    "        \"Nuclei_Location_Center_Y\": \"Metadata_Nuclei_Location_Center_Y\",\n",
    "        \"Nuclei_Location_Center_X\": \"Metadata_Nuclei_Location_Center_X\",\n",
    "    }\n",
    "    # Image_FileName cols\n",
    "    for col in annotated_df.columns:\n",
    "        if \"Image_FileName\" in col:\n",
    "            columns_to_rename[col] = f\"Metadata_{col}\"\n",
    "        elif \"Image_PathName\" in col:\n",
    "            columns_to_rename[col] = f\"Metadata_{col}\"\n",
    "        elif \"TrackObjects\" in col:\n",
    "            columns_to_rename[col] = f\"Metadata_{col}\"\n",
    "    # rename metadata columns\n",
    "    annotated_df.rename(columns=columns_to_rename, inplace=True)\n",
    "\n",
    "    info[\"output_file\"].parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # save annotated df as parquet file\n",
    "    output(\n",
    "        df=annotated_df,\n",
    "        output_filename=info[\"output_file\"],\n",
    "        output_type=\"parquet\",\n",
    "    )\n",
    "    print(\n",
    "        f\"Annotations have been added to {data_run} and saved to {info['output_file']}\"\n",
    "    )\n",
    "    # check last annotated df to see if it has been annotated correctly\n",
    "    print(annotated_df.shape)\n",
    "    annotated_df.head()\n",
    "del annotated_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellprofiler_timelapse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
